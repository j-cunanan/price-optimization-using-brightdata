# ğŸš€ Japanese Marketplace Price Monitor

A comprehensive price monitoring ```
scrape_everything/
â”œâ”€â”€ ğŸš€ price_monitor.sh           # Main automation script
â”œâ”€â”€ ğŸ“‹ QUICK_START.md             # Complete usage guide  
â”œâ”€â”€ ğŸ“Š sample_keywords.txt        # Your search keywords
â”œâ”€â”€ ğŸŒ dashboard/                 # Web interface
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ canonical/                # Master product database
â”‚   â”œâ”€â”€ batch/results/           # Raw scraping results  
â”‚   â””â”€â”€ monitor.log              # Activity logs
â””â”€â”€ ğŸ”§ src/                      # Core scraping engine
    â”œâ”€â”€ cli/                     # Command-line tools
    â”‚   â”œâ”€â”€ import_batch_results.py  # Import batch data
    â”‚   â””â”€â”€ monitor_canonical.py     # Monitor system
    â”œâ”€â”€ brightdata/              # Bright Data integration
    â””â”€â”€ canonical_products_simple.py # Product management
```anese e-commerce platforms (Amazon.jp, Rakuten, Yahoo Shopping) powered by Bright Data's premium proxy network.

## âš¡ Quick Start

**Want to get started immediately?** See [QUICK_START.md](QUICK_START.md) for the single-command setup!

```bash
# Complete workflow: scrape â†’ import â†’ monitor â†’ dashboard
./price_monitor.sh -d
```

## ğŸ¯ Key Features

- **ğŸª Multi-platform**: Amazon JP, Rakuten, Yahoo Shopping  
- **ğŸ’° Price Tracking**: Automatic price change detection
- **ğŸ“Š Dashboard**: Real-time web interface at http://localhost:8000
- **ğŸ”„ Automation**: Single command handles entire workflow
- **ğŸŒ Bright Data**: Premium proxy network with anti-detection
- **ğŸ“ˆ Canonical System**: Smart product deduplication and tracking

## ğŸ“‹ Prerequisites

- Python 3.10+ 
- UV package manager (`curl -LsSf https://astral.sh/uv/install.sh | sh`)
- Chrome/Chromium browser
- Bright Data account (for premium features)

## ğŸš€ Installation

```bash
git clone <your-repo-url>
cd scrape_everything
uv sync
cp .env.example .env  # Add your Bright Data credentials
```

**Most Common Use Cases:**

```bash
# Daily status check (30 seconds)
./price_monitor.sh --monitor-only

# Weekly full update (5-10 minutes)  
./price_monitor.sh -d

# Check specific products
echo "iPhone 15 Pro" > temp_keywords.txt
./price_monitor.sh -k temp_keywords.txt -l 20
```

**See [QUICK_START.md](QUICK_START.md) for all commands and options!**

## ğŸ“Š What You Get

- **ğŸ“ Product Database**: `data/canonical/products.json` - Your master product catalog
- **ğŸ’° Price Changes**: Real-time detection of price drops and increases  
- **ğŸ“ˆ Dashboard**: Beautiful web interface at http://localhost:8000
- **ğŸ“‹ Reports**: Detailed logs in `data/monitor.log`
- **ğŸ”„ Automation**: Runs completely hands-free

## ğŸ—ï¸ Architecture

```
./price_monitor.sh
â”œâ”€â”€ ğŸ” Discovery: Scrape marketplaces using Bright Data
â”œâ”€â”€ ï¿½ Import: Process results into canonical database  
â”œâ”€â”€ ï¿½ Monitor: Detect price changes and trends
â””â”€â”€ ğŸŒ Dashboard: Visualize data in web interface
```

## ğŸ“ Project Structure

```
scrape_everything/
â”œâ”€â”€ ğŸš€ price_monitor.sh           # Main automation script
â”œâ”€â”€ ğŸ“‹ QUICK_START.md             # Complete usage guide  
â”œâ”€â”€ ğŸ“Š sample_keywords.txt        # Your search keywords
â”œâ”€â”€ ğŸŒ dashboard/                 # Web interface
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ canonical/                # Master product database
â”‚   â”œâ”€â”€ batch/results/           # Raw scraping results  
â”‚   â””â”€â”€ monitor.log              # Activity logs
â””â”€â”€ ï¿½ src/                      # Core scraping engine
    â”œâ”€â”€ brightdata/              # Bright Data integration
    â””â”€â”€ canonical_products_simple.py # Product management
```

## ğŸš€ Next Steps

1. **Start here**: Read [QUICK_START.md](QUICK_START.md) 
2. **Dashboard**: Check [dashboard/README.md](dashboard/README.md)
3. **First run**: `./price_monitor.sh --monitor-only`
4. **Weekly update**: `./price_monitor.sh -d`

## ğŸ“ Support

For questions about Bright Data integration or advanced features, check the inline documentation or logs at `data/monitor.log`.

---

**ğŸ¯ This system is designed for simplicity: One script, one command, complete price monitoring!**
TIMEOUT=30

# User agent rotation
ROTATE_USER_AGENTS=true

# Output settings
DEFAULT_OUTPUT_FORMAT=csv
SAVE_IMAGES=false

# Email alerts (optional)
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_USER=your@email.com
EMAIL_PASS=your_app_password
```

## CLI Options

```bash
# Search options
--search, -s KEYWORD          Search keyword (required)
--platforms, -p PLATFORMS     Specific platforms: amazon_jp, rakuten, mercari, yahoo_shopping
--max-results, -m NUMBER      Maximum results per platform (default: 20)

# Filters
--min-price PRICE            Minimum price in JPY
--max-price PRICE            Maximum price in JPY
--condition CONDITION        Product condition: new, like_new, good, acceptable, poor

# Output options
--output, -o FILE            Output file (CSV/JSON based on extension)
--format, -f FORMAT          Output format: csv, json (default: csv)
--show-top NUMBER           Show top N lowest price products (default: 10)
--show-comparison           Show platform comparison statistics

# Configuration
--log-level LEVEL           Logging level: DEBUG, INFO, WARNING, ERROR
--concurrent NUMBER         Max concurrent requests (default: 5)
--delay SECONDS            Delay between requests (default: 1.0)
```

## Scraping Method Comparison

| Feature | DIY Scraping | Bright Data API |
|---------|-------------|-----------------|
| **Cost** | Free | Paid service |
| **Setup** | Quick, no external dependencies | Requires account setup |
| **Speed** | Very fast (direct HTTP) | Moderate (browser-based) |
| **Reliability** | Good for simple sites | Excellent for complex sites |
| **Anti-detection** | Basic (user agents, delays) | Advanced (residential IPs, browser profiles) |
| **Blocking resistance** | Moderate | High |
| **Maintenance** | Requires updates for site changes | Managed by Bright Data |
| **Proxy network** | None | Global proxy network |
| **JavaScript support** | Limited | Full (real browser) |

### When to use DIY Scraping:
- âœ… Learning and development
- âœ… Simple, stable websites
- âœ… High-volume, fast scraping
- âœ… Budget constraints
- âœ… Full control over logic

### When to use Bright Data:
- âœ… Production environments
- âœ… Complex, anti-bot protected sites
- âœ… Long-term stability requirements
- âœ… Compliance and legal considerations
- âœ… Reduced maintenance overhead

## Examples

### Search Nintendo Switch across all platforms (DIY)
```bash
uv run python main.py --search "Nintendo Switch" --max-results 5
```

### Search with Bright Data
```bash
uv run python -m src.brightdata.scraper "Nintendo Switch" --max-results 5
```

### Compare both methods
```bash
uv run python compare_scrapers.py "iPhone 15" --platforms amazon --output-file comparison.json
```

### Compare prices on Amazon and Rakuten
```bash
uv run python main.py --search "iPhone 15" --platforms amazon_jp rakuten --show-comparison
```

### Filter by price range and export to CSV
```bash
uv run python main.py --search "MacBook" --min-price 100000 --max-price 300000 --output macbooks.csv
```

### Search used items with condition filter
```bash
uv run python main.py --search "Camera" --condition good --platforms mercari --max-results 10
```

## Legal Notice

This scraper is for educational and research purposes only. Please:
- Respect robots.txt files
- Follow platform terms of service
- Use reasonable request rates
- Don't overload servers
- Consider using official APIs when available
- Review Bright Data's terms of service for commercial usage

## License

MIT License - see LICENSE file for details.
